{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f105a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'base (Python 3.10.18)' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: 'conda install -n base ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "# Customer Churn Analysis - Exploratory Data Analysis\n",
    "## GlobalStream Inc. - STANDARD Package Delivery\n",
    "\n",
    "### 1. Project Overview\n",
    "- **Client**: GlobalStream Inc.\n",
    "- **Objective**: Identify key drivers of customer churn\n",
    "- **Dataset**: 5,000 customers, 15 features\n",
    "- **Timeline**: 2-week analysis\n",
    "\n",
    "### 2. Initial Data Assessment\n",
    "\"\"\"\n",
    "\n",
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from data_processing import DataProcessor\n",
    "from feature_engineering import FeatureEngineer\n",
    "from exploratory_analysis import EDA\n",
    "\n",
    "# Load and inspect data\n",
    "print(\"📁 Loading customer data...\")\n",
    "processor = DataProcessor('data/raw/customer_data.csv')\n",
    "processor.load_data()\n",
    "\n",
    "print(\"\\\\n📋 Data Overview:\")\n",
    "print(f\"Shape: {processor.df.shape}\")\n",
    "print(f\"Columns: {list(processor.df.columns)}\")\n",
    "\n",
    "print(\"\\\\n📊 First look at the data:\")\n",
    "display(processor.df.head())\n",
    "\n",
    "print(\"\\\\n🔍 Data types and missing values:\")\n",
    "display(processor.df.info())\n",
    "\n",
    "\"\"\"\n",
    "### 3. Data Quality Assessment\n",
    "\"\"\"\n",
    "\n",
    "# Check for missing values\n",
    "missing_data = processor.df.isnull().sum()\n",
    "missing_percent = (missing_data / len(processor.df)) * 100\n",
    "\n",
    "print(\"\\\\n📉 Missing Value Analysis:\")\n",
    "missing_report = pd.DataFrame({\n",
    "    'missing_count': missing_data,\n",
    "    'missing_percent': missing_percent\n",
    "}).sort_values('missing_percent', ascending=False)\n",
    "\n",
    "display(missing_report[missing_report['missing_count'] > 0])\n",
    "\n",
    "\"\"\"\n",
    "### 4. Target Variable Analysis\n",
    "\"\"\"\n",
    "\n",
    "# Analyze churn distribution\n",
    "if 'churn' in processor.df.columns:\n",
    "    churn_distribution = processor.df['churn'].value_counts()\n",
    "    churn_rate = processor.df['churn'].mean()\n",
    "    \n",
    "    print(f\"\\\\n🎯 Churn Distribution:\")\n",
    "    print(f\"Retained: {churn_distribution[0]:,} customers ({churn_distribution[0]/len(processor.df):.1%})\")\n",
    "    print(f\"Churned: {churn_distribution[1]:,} customers ({churn_distribution[1]/len(processor.df):.1%})\")\n",
    "    print(f\"Overall Churn Rate: {churn_rate:.1%}\")\n",
    "\n",
    "    # Visualize churn distribution\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.pie(churn_distribution, labels=['Retained', 'Churned'], autopct='%1.1f%%', \n",
    "            colors=['lightblue', 'lightcoral'], startangle=90)\n",
    "    plt.title('Customer Churn Distribution')\n",
    "    plt.show()\n",
    "\n",
    "\"\"\"\n",
    "### 5. Feature Distributions\n",
    "\"\"\"\n",
    "\n",
    "# Analyze numerical features\n",
    "numerical_cols = processor.df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "print(\"\\\\n📈 Numerical Features Summary:\")\n",
    "display(processor.df[numerical_cols].describe())\n",
    "\n",
    "# Create distribution plots for key numerical features\n",
    "key_numerical = ['monthly_charges', 'tenure_days', 'viewing_hours', 'devices_connected']\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, col in enumerate(key_numerical):\n",
    "    if col in processor.df.columns:\n",
    "        processor.df[col].hist(bins=30, ax=axes[i], alpha=0.7, color='steelblue')\n",
    "        axes[i].set_title(f'Distribution of {col}')\n",
    "        axes[i].set_xlabel(col)\n",
    "        axes[i].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\"\"\"\n",
    "### 6. Initial Correlation Analysis\n",
    "\"\"\"\n",
    "\n",
    "# Calculate correlations with churn\n",
    "if 'churn' in processor.df.columns:\n",
    "    numerical_with_churn = numerical_cols.tolist() + ['churn']\n",
    "    correlation_matrix = processor.df[numerical_with_churn].corr()\n",
    "    \n",
    "    # Focus on churn correlations\n",
    "    churn_correlations = correlation_matrix['churn'].sort_values(ascending=False)\n",
    "    \n",
    "    print(\"\\\\n🔗 Correlation with Churn:\")\n",
    "    display(pd.DataFrame(churn_correlations).T)\n",
    "\n",
    "\"\"\"\n",
    "### 7. Next Steps\n",
    "Based on initial analysis, we will proceed with:\n",
    "1. Data cleaning and preprocessing\n",
    "2. Advanced feature engineering\n",
    "3. Deep-dive statistical analysis\n",
    "4. Customer segmentation\n",
    "5. Insight generation and recommendations\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
